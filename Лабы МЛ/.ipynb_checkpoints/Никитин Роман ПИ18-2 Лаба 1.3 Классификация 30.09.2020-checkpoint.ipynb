{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Предсказанные значения')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scikitplot\n",
    "import  numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', \n",
    "             'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "pima = pd.read_csv('diabetes.csv', header=None, names=col_names)\n",
    "pima = pima[1:]\n",
    "pima.head()\n",
    "\n",
    "Y = pima.label\n",
    "X = pima.drop(['label'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2,\n",
    "                                                   random_state=True)\n",
    "\n",
    "\n",
    "cls = LogisticRegression()\n",
    "cls.fit(x_train, y_train)\n",
    "y_pred = cls.predict(x_test)\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "%matplotlib inline\n",
    " \n",
    "class_names = [0, 1]\n",
    "fig, ax = plt.subplots()\n",
    "ticks = np.arange(len(class_names))\n",
    "plt.xticks(ticks, class_names)\n",
    "plt.yticks(ticks, class_names)\n",
    "sns.heatmap(pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_test, y_pred)),\n",
    "    annot=True)\n",
    "\n",
    "plt.ylabel('Действительные значения')\n",
    "plt.xlabel('Предсказанные значения')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо предсказали 0 класс, но 1 класс остался совсем без \"внимания\" модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy — доля правильных ответов алгоритма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78761062, 0.75609756])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, y_pred, average=None, zero_division=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8989899 , 0.56363636])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_pred, average=None, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из большой разницы в количестве элементов каждого класса, если сказать, что все элементы принадлежат к классу 0, аакьюрэси будет равен числу ниже. Это означает, что accurasy = 0.78- результат не из лучших."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510416666666666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "500/(500+268)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная по модель не лучшая из возможных, лучше бы ее оптимизировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17</td>\n",
       "      <td>136</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>186</td>\n",
       "      <td>248</td>\n",
       "      <td>517</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.258</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>135</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>227</td>\n",
       "      <td>374</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pregnant glucose   bp skin insulin  bmi pedigree  age\n",
       "count       768     768  768  768     768  768      768  768\n",
       "unique       17     136   47   51     186  248      517   52\n",
       "top           1      99   70    0       0   32    0.258   22\n",
       "freq        135      17   57  227     374   13        6   72"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяю нормализацию данных, чтобы избежать конфузов с неправильным интерплетированием параметров моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "out = pd.DataFrame(scaler.transform(X), columns=['pregnant', 'glucose', 'bp', 'skin', \n",
    "             'insulin', 'bmi', 'pedigree', 'age'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(out, Y, \n",
    "                                                    test_size=0.2,\n",
    "                                                   random_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant   glucose        bp      skin   insulin       bmi  pedigree  \\\n",
       "0  0.639947  0.848324  0.149641  0.907270 -0.692891  0.204013  0.468492   \n",
       "1 -0.844885 -1.123396 -0.160546  0.530902 -0.692891 -0.684422 -0.365061   \n",
       "2  1.233880  1.943724 -0.263941 -1.288212 -0.692891 -1.103255  0.604397   \n",
       "3 -0.844885 -0.998208 -0.160546  0.154533  0.123302 -0.494043 -0.920763   \n",
       "4 -1.141852  0.504055 -1.504687  0.907270  0.765836  1.409746  5.484909   \n",
       "\n",
       "        age  \n",
       "0  1.425995  \n",
       "1 -0.190672  \n",
       "2 -0.105584  \n",
       "3 -1.041549  \n",
       "4 -0.020496  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализовал данные из за слишком больших размахов между фичами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаю переменную params для передачи параметров в GridSearchsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel': ['linear', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto', 'float'], 'class_weight': ['balanced', None], 'C':[0.1,0.2,0.5,2,3,4,5,6,7,8,9,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCVSVC = GridSearchCV(clf, params, verbose=1, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаю на всей выборке, так как все равно будет кросс-валидация и особо не переобучу (потом будет проверочка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 585 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.2, 0.5, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'gamma': ['scale', 'auto', 'float'],\n",
       "                         'kernel': ['linear', 'rbf', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCVSVC.fit(out, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 6, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCVSVC.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше- параметры модели, на которых она показала наилучший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01196527, 0.01762072, 0.01882688, 0.00490713, 0.02003026,\n",
       "        0.01276533, 0.00269945, 0.00398946, 0.00332292, 0.0069801 ,\n",
       "        0.00964061, 0.01396179, 0.00930778, 0.01030588, 0.01097409,\n",
       "        0.00266059, 0.00265821, 0.00199413, 0.00731405, 0.01230105,\n",
       "        0.01263277, 0.00964133, 0.01529368, 0.01428962, 0.00465608,\n",
       "        0.00398819, 0.00498215, 0.00930564, 0.01363349, 0.01162656,\n",
       "        0.01197767, 0.01329048, 0.0123016 , 0.00299279, 0.00299311,\n",
       "        0.00299136, 0.01062298, 0.01495679, 0.01230105, 0.01030278,\n",
       "        0.01263229, 0.01428986, 0.00415969, 0.0043234 , 0.00465345,\n",
       "        0.01928107, 0.01163514, 0.01130851, 0.01595855, 0.01097083,\n",
       "        0.01329676, 0.00431673, 0.0049909 , 0.00416533, 0.01794958,\n",
       "        0.01329859, 0.01031009, 0.01961406, 0.01396362, 0.01130923,\n",
       "        0.00399041, 0.00431919, 0.00365734, 0.01861668, 0.01362618,\n",
       "        0.00963982, 0.01795236, 0.01229103, 0.01129206, 0.00301369,\n",
       "        0.00299462, 0.00498772, 0.02392975, 0.01396394, 0.01030095,\n",
       "        0.02560274, 0.01396203, 0.01163673, 0.00432173, 0.00501156,\n",
       "        0.00365718, 0.02094658, 0.01695124, 0.00962758, 0.02061113,\n",
       "        0.01429303, 0.01230923, 0.00332785, 0.00299152, 0.00331847,\n",
       "        0.02592699, 0.01462738, 0.0103054 , 0.02227283, 0.0126315 ,\n",
       "        0.00997965, 0.00366131, 0.00332546, 0.00465266, 0.02493254,\n",
       "        0.01230383, 0.00997448, 0.02559821, 0.01196901, 0.00897662,\n",
       "        0.00397825, 0.00365655, 0.00398731, 0.02792223, 0.01329788,\n",
       "        0.01030556, 0.02825801, 0.01562126, 0.00964014, 0.00299223,\n",
       "        0.00299827, 0.00299263, 0.03125207, 0.01163554, 0.00864299,\n",
       "        0.03158132, 0.01462897, 0.00930603, 0.00265996, 0.0029858 ,\n",
       "        0.00332133, 0.03390773, 0.01562699, 0.01030135, 0.0335749 ,\n",
       "        0.0149591 , 0.00930683, 0.00376415, 0.00398986, 0.00432054,\n",
       "        0.04033605, 0.01462833, 0.00930643, 0.04022233, 0.01396139,\n",
       "        0.01040872, 0.00298905, 0.00431911, 0.00332324, 0.04232661,\n",
       "        0.0152878 , 0.00997265, 0.04279844, 0.02060715, 0.01096924,\n",
       "        0.00475947, 0.00299056, 0.00598478, 0.0438803 , 0.01529272,\n",
       "        0.0093108 , 0.03922669, 0.02094539, 0.01096916, 0.00365734,\n",
       "        0.00365885, 0.00332427, 0.03997787, 0.01728948, 0.0109748 ,\n",
       "        0.04554311, 0.01595672, 0.01030509, 0.00299231, 0.00432181,\n",
       "        0.0029854 , 0.04321686, 0.01628915, 0.01063712, 0.04288507,\n",
       "        0.01961199, 0.00930913, 0.00265853, 0.00431506, 0.0039862 ,\n",
       "        0.04156057, 0.01960985, 0.01163491, 0.04255199, 0.0176204 ,\n",
       "        0.01562166, 0.00299311, 0.0049874 , 0.00432348, 0.05717913,\n",
       "        0.01628788, 0.00864156, 0.05319111, 0.0146273 , 0.01197044,\n",
       "        0.00265797, 0.00365527, 0.00332419, 0.04820363, 0.01628844,\n",
       "        0.00965389, 0.04388245, 0.01994626, 0.00997368, 0.00332435,\n",
       "        0.00332554, 0.00332284, 0.04787493, 0.0149587 , 0.00930858,\n",
       "        0.04687691, 0.01496331, 0.00863846, 0.00332459, 0.00232792,\n",
       "        0.00232689]),\n",
       " 'std_fit_time': array([8.48537942e-07, 3.85163199e-03, 3.91879464e-03, 4.07292620e-03,\n",
       "        2.32324181e-03, 2.84697497e-04, 4.15288590e-04, 8.13420485e-04,\n",
       "        4.66088965e-04, 8.13420610e-04, 1.24411268e-03, 2.15453530e-03,\n",
       "        2.61858499e-03, 4.70528635e-04, 1.41450452e-03, 4.70077941e-04,\n",
       "        4.70583774e-04, 8.14103900e-04, 9.40436927e-04, 9.40943429e-04,\n",
       "        4.68954187e-04, 4.71155866e-04, 4.69982335e-03, 1.69655955e-03,\n",
       "        1.69753942e-03, 8.14690631e-04, 2.15538193e-03, 4.69741170e-04,\n",
       "        3.84651139e-03, 4.65159651e-04, 5.65458982e-03, 4.02119729e-03,\n",
       "        4.70247445e-04, 8.15658738e-04, 1.27652315e-06, 8.13615277e-04,\n",
       "        4.90589355e-04, 3.55115546e-03, 9.41448451e-04, 4.65807061e-04,\n",
       "        9.39594731e-04, 3.28441966e-03, 1.30683707e-03, 4.69234954e-04,\n",
       "        1.69137282e-03, 1.03427242e-02, 1.24377386e-03, 4.68366501e-04,\n",
       "        2.93642383e-03, 8.14393406e-04, 1.69540416e-03, 1.88335278e-03,\n",
       "        2.82277151e-03, 1.04001134e-03, 8.14986616e-04, 9.39425402e-04,\n",
       "        4.66583244e-04, 4.70249017e-04, 2.44591466e-03, 1.87028944e-03,\n",
       "        1.41175117e-03, 1.24145780e-03, 4.71539433e-04, 3.08301223e-03,\n",
       "        4.66397458e-04, 1.23950534e-03, 8.14393623e-04, 1.25434050e-03,\n",
       "        4.77220434e-04, 3.30387327e-05, 2.28130024e-06, 8.14699066e-04,\n",
       "        2.15783022e-03, 2.21100294e-06, 4.67438107e-04, 9.48023292e-04,\n",
       "        1.41023358e-03, 9.42066378e-04, 9.40665698e-04, 8.44040765e-04,\n",
       "        4.70250467e-04, 1.41366987e-03, 3.73344410e-03, 9.36357779e-04,\n",
       "        1.24141988e-03, 2.04864799e-03, 1.68236291e-03, 4.66835551e-04,\n",
       "        2.59232623e-06, 4.75182936e-04, 2.15748064e-03, 2.35286192e-03,\n",
       "        1.88059250e-03, 4.71201857e-04, 4.69740766e-04, 8.08362997e-04,\n",
       "        4.72351767e-04, 4.69685125e-04, 4.71315374e-04, 2.15284317e-03,\n",
       "        1.24541761e-03, 8.08786832e-04, 2.61886738e-03, 2.61416184e-06,\n",
       "        1.40933445e-03, 8.30595331e-04, 1.69630826e-03, 8.16632348e-04,\n",
       "        1.41231280e-03, 1.24277493e-03, 4.70079070e-04, 2.85976002e-03,\n",
       "        2.35410093e-03, 4.70640624e-04, 2.97360213e-07, 8.14622344e-04,\n",
       "        1.36267568e-06, 2.86139554e-03, 4.70359192e-04, 4.70415035e-04,\n",
       "        4.01615618e-03, 1.69306639e-03, 9.38245367e-04, 4.70135054e-04,\n",
       "        8.09526785e-04, 4.73136462e-04, 2.82119766e-03, 2.48901164e-03,\n",
       "        4.72583033e-04, 1.69460936e-03, 1.62732699e-03, 1.24237107e-03,\n",
       "        5.60923205e-04, 1.41062741e-03, 1.24205347e-03, 8.84259058e-03,\n",
       "        4.80115048e-04, 1.87755793e-03, 1.09896255e-02, 1.41029109e-03,\n",
       "        1.79944201e-03, 1.87730977e-06, 4.69916077e-04, 4.69235923e-04,\n",
       "        8.83162587e-03, 4.62154899e-04, 7.86741172e-07, 3.70232819e-03,\n",
       "        6.00764625e-03, 2.82057955e-03, 6.08294260e-04, 2.13544032e-06,\n",
       "        1.41073953e-03, 2.15508748e-03, 1.24404905e-03, 9.44017661e-04,\n",
       "        5.23571659e-03, 6.51534178e-03, 2.44230416e-03, 9.40549681e-04,\n",
       "        4.75505014e-04, 4.71201776e-04, 3.02595766e-03, 1.24729871e-03,\n",
       "        8.18384112e-04, 3.39027836e-03, 1.62869177e-03, 1.24326476e-03,\n",
       "        1.80877156e-06, 4.70360280e-04, 8.07104640e-04, 6.16740433e-03,\n",
       "        1.69587238e-03, 1.24224834e-03, 4.07167500e-03, 4.01377009e-03,\n",
       "        4.69459858e-04, 9.40436927e-04, 9.35455995e-04, 1.41355748e-03,\n",
       "        2.49376982e-03, 3.29648177e-03, 9.39987159e-04, 3.67336101e-03,\n",
       "        2.35983386e-03, 4.09271969e-03, 7.78671819e-07, 8.14200584e-04,\n",
       "        4.68021926e-04, 3.76197168e-03, 9.40099631e-04, 4.69410857e-04,\n",
       "        1.69535738e-03, 4.68560604e-04, 3.73178606e-03, 4.68901012e-04,\n",
       "        9.39820965e-04, 9.42347583e-04, 7.11220955e-03, 9.40324334e-04,\n",
       "        4.80455117e-04, 2.93676905e-03, 5.64250769e-03, 8.15075106e-04,\n",
       "        4.70976993e-04, 4.71988758e-04, 4.69518162e-04, 7.09688185e-03,\n",
       "        8.14393623e-04, 9.41223426e-04, 5.70335399e-03, 1.41720183e-03,\n",
       "        9.44386682e-04, 1.24373034e-03, 4.70527427e-04, 4.71426560e-04]),\n",
       " 'mean_score_time': array([0.00365829, 0.00565012, 0.00631642, 0.00785486, 0.00664878,\n",
       "        0.00498796, 0.        , 0.        , 0.        , 0.00199421,\n",
       "        0.00531991, 0.00665021, 0.00432205, 0.00466061, 0.00565751,\n",
       "        0.        , 0.        , 0.        , 0.00365734, 0.00465473,\n",
       "        0.00631579, 0.00299056, 0.00598423, 0.0056537 , 0.        ,\n",
       "        0.        , 0.        , 0.00266004, 0.00598057, 0.00498668,\n",
       "        0.00298262, 0.00498684, 0.00499471, 0.        , 0.        ,\n",
       "        0.        , 0.00299255, 0.00432483, 0.00498621, 0.00299215,\n",
       "        0.00465536, 0.01363587, 0.        , 0.        , 0.        ,\n",
       "        0.00316119, 0.00532873, 0.00532142, 0.00283051, 0.00565298,\n",
       "        0.00432332, 0.        , 0.        , 0.        , 0.0026598 ,\n",
       "        0.00465457, 0.00498605, 0.00265932, 0.00532118, 0.00431291,\n",
       "        0.        , 0.        , 0.        , 0.00266314, 0.00498613,\n",
       "        0.00432245, 0.00299128, 0.00598391, 0.00398962, 0.        ,\n",
       "        0.        , 0.        , 0.00365718, 0.00399399, 0.00332467,\n",
       "        0.00298564, 0.0139633 , 0.00565092, 0.        , 0.        ,\n",
       "        0.        , 0.00332157, 0.00399041, 0.00365694, 0.00465385,\n",
       "        0.00432698, 0.00364963, 0.        , 0.        , 0.        ,\n",
       "        0.00299271, 0.00465584, 0.00332562, 0.00299303, 0.00432293,\n",
       "        0.00664616, 0.        , 0.        , 0.        , 0.002659  ,\n",
       "        0.00365241, 0.00498382, 0.00299311, 0.0039885 , 0.00465536,\n",
       "        0.        , 0.        , 0.        , 0.00299764, 0.00399025,\n",
       "        0.00398978, 0.00332602, 0.00432229, 0.00299287, 0.        ,\n",
       "        0.        , 0.        , 0.00332499, 0.00399041, 0.00365861,\n",
       "        0.00333699, 0.00476082, 0.00365694, 0.        , 0.        ,\n",
       "        0.        , 0.00299358, 0.00498621, 0.0036598 , 0.00299279,\n",
       "        0.00432205, 0.00398962, 0.        , 0.        , 0.        ,\n",
       "        0.00331998, 0.00431705, 0.00332554, 0.00332427, 0.00432825,\n",
       "        0.00432142, 0.        , 0.        , 0.        , 0.00365917,\n",
       "        0.00498581, 0.00498811, 0.00324543, 0.00432165, 0.00598431,\n",
       "        0.        , 0.        , 0.        , 0.00332665, 0.00365869,\n",
       "        0.00393017, 0.00299398, 0.00498549, 0.00398858, 0.        ,\n",
       "        0.        , 0.        , 0.00291197, 0.00431895, 0.00464892,\n",
       "        0.0033257 , 0.00465337, 0.00432324, 0.        , 0.        ,\n",
       "        0.        , 0.0023272 , 0.00398938, 0.00398835, 0.00332808,\n",
       "        0.00398779, 0.00398835, 0.        , 0.        , 0.        ,\n",
       "        0.00332141, 0.00565076, 0.00399192, 0.00299374, 0.00464932,\n",
       "        0.00432412, 0.        , 0.        , 0.        , 0.00299072,\n",
       "        0.00398842, 0.00365686, 0.00565386, 0.00398874, 0.00398755,\n",
       "        0.        , 0.        , 0.        , 0.00299088, 0.00398914,\n",
       "        0.00364415, 0.00265972, 0.00432165, 0.00465409, 0.        ,\n",
       "        0.        , 0.        , 0.00332133, 0.00399025, 0.00332546,\n",
       "        0.00365527, 0.00398493, 0.00366282, 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'std_score_time': array([4.69853158e-04, 4.69413199e-04, 1.24394287e-03, 7.85082906e-03,\n",
       "        1.69730573e-03, 1.87730977e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.49566384e-07, 4.70302885e-04, 9.41055337e-04,\n",
       "        1.87958086e-03, 4.62266634e-04, 4.67896581e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.72888131e-04, 4.67213325e-04,\n",
       "        2.04965372e-03, 2.59232623e-06, 8.14296062e-04, 1.24346271e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.70864602e-04,\n",
       "        2.15714910e-03, 1.10692885e-06, 8.03511243e-04, 7.37000982e-07,\n",
       "        1.34593336e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.25153985e-06, 4.73787583e-04, 1.17340271e-06, 1.73024663e-06,\n",
       "        4.72720055e-04, 6.11014223e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.39731986e-04, 9.44827578e-04, 4.68401695e-04,\n",
       "        2.30292437e-04, 2.35308667e-03, 4.69798323e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.71033219e-04, 4.71493033e-04,\n",
       "        2.15420509e-03, 4.69853158e-04, 1.24613304e-03, 4.56928044e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.71379398e-04,\n",
       "        8.14787377e-04, 4.68730859e-04, 1.46109075e-06, 2.15493992e-03,\n",
       "        1.57348234e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.70753015e-04, 9.53872978e-06, 4.69235075e-04, 8.06483125e-06,\n",
       "        4.95494572e-03, 1.69626136e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.62155719e-04, 2.02304873e-06, 4.69742380e-04,\n",
       "        1.69607595e-03, 4.77834070e-04, 9.29815857e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.10467325e-07, 4.69859368e-04,\n",
       "        4.69242828e-04, 9.60274217e-07, 4.69573541e-04, 2.48801935e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.71820282e-04,\n",
       "        4.74124038e-04, 1.40540099e-03, 8.12836901e-04, 8.15759984e-04,\n",
       "        9.40212305e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.27482188e-06, 1.23630756e-06, 8.13713362e-04, 4.69628375e-04,\n",
       "        4.68005448e-04, 7.78671819e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.73899175e-04, 2.43140197e-06, 4.70415519e-04,\n",
       "        4.86319059e-04, 5.61319109e-04, 4.70077941e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.14491350e-04, 8.13032579e-04,\n",
       "        4.71932954e-04, 1.40826266e-06, 4.70864682e-04, 1.12391596e-07,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.62436461e-04,\n",
       "        4.63278527e-04, 4.70976993e-04, 4.70024235e-04, 4.68879137e-04,\n",
       "        1.24271083e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.72334117e-04, 8.12451764e-04, 1.62878687e-03, 3.68857729e-04,\n",
       "        4.70303449e-04, 2.82131005e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.70021816e-04, 4.71148144e-04, 8.68789218e-05,\n",
       "        9.60274217e-07, 7.86741172e-07, 1.12391596e-07, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.30255913e-04, 4.66312894e-04,\n",
       "        1.24534723e-03, 4.70023106e-04, 4.70302644e-04, 4.68844463e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.70021816e-04,\n",
       "        8.13907215e-04, 8.14492963e-04, 4.70197586e-04, 1.68587394e-06,\n",
       "        1.07214749e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.72392146e-04, 1.69576261e-03, 8.14977441e-04, 1.07214749e-06,\n",
       "        9.41632568e-04, 4.68747837e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.15042996e-07, 5.61957980e-07, 4.70021695e-04,\n",
       "        1.24043879e-03, 1.36267568e-06, 8.12836202e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.32507737e-06, 4.49566384e-07,\n",
       "        4.88678698e-04, 4.70302885e-04, 4.71145611e-04, 1.69551326e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.73466417e-04,\n",
       "        1.29616312e-06, 4.71034627e-04, 9.42689984e-04, 6.75472557e-06,\n",
       "        4.73255094e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', None, None, None, None, None, None, None,\n",
       "                    None, None, 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', None, None, None, None, None,\n",
       "                    None, None, None, None, 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', None, None, None,\n",
       "                    None, None, None, None, None, None, 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced', None,\n",
       "                    None, None, None, None, None, None, None, None,\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', None, None, None, None, None, None, None,\n",
       "                    None, None, 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', None, None, None, None, None,\n",
       "                    None, None, None, None, 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', None, None, None,\n",
       "                    None, None, None, None, None, None, 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced', None,\n",
       "                    None, None, None, None, None, None, None, None,\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', None, None, None, None, None, None, None,\n",
       "                    None, None, 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', None, None, None, None, None,\n",
       "                    None, None, None, None, 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', None, None, None,\n",
       "                    None, None, None, None, None, None, 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced', None,\n",
       "                    None, None, None, None, None, None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=['scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'float', 'float', 'float', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'float', 'float', 'float'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid',\n",
       "                    'linear', 'rbf', 'sigmoid', 'linear', 'rbf', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1,\n",
       "   'class_weight': 'balanced',\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'linear'},\n",
       "  {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 0.1,\n",
       "   'class_weight': 'balanced',\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 0.1,\n",
       "   'class_weight': 'balanced',\n",
       "   'gamma': 'float',\n",
       "   'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.2, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 0.2, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 0.2,\n",
       "   'class_weight': 'balanced',\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'sigmoid'},\n",
       "  {'C': 0.2, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 0.2, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 0.2, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.2, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 0.2, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 0.2,\n",
       "   'class_weight': 'balanced',\n",
       "   'gamma': 'float',\n",
       "   'kernel': 'sigmoid'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 0.2, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.5, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 0.5,\n",
       "   'class_weight': 'balanced',\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'sigmoid'},\n",
       "  {'C': 0.5, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.5, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 0.5,\n",
       "   'class_weight': 'balanced',\n",
       "   'gamma': 'float',\n",
       "   'kernel': 'sigmoid'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 2, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 2, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 3, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 3, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 4, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 4, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 5, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 5, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 6, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 6, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 7, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 7, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 8, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 8, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 9, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 9, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 10, 'class_weight': 'balanced', 'gamma': 'float', 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'linear'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'float', 'kernel': 'linear'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'float', 'kernel': 'rbf'},\n",
       "  {'C': 10, 'class_weight': None, 'gamma': 'float', 'kernel': 'sigmoid'}],\n",
       " 'split0_test_score': array([0.7265625 , 0.71484375, 0.73046875, 0.7265625 , 0.71484375,\n",
       "        0.73046875,        nan,        nan,        nan, 0.76953125,\n",
       "        0.75      , 0.765625  , 0.76953125, 0.75390625, 0.765625  ,\n",
       "               nan,        nan,        nan, 0.73046875, 0.72265625,\n",
       "        0.72265625, 0.73046875, 0.72265625, 0.734375  ,        nan,\n",
       "               nan,        nan, 0.765625  , 0.77734375, 0.7421875 ,\n",
       "        0.765625  , 0.7734375 , 0.7421875 ,        nan,        nan,\n",
       "               nan, 0.73828125, 0.7109375 , 0.71484375, 0.73828125,\n",
       "        0.7109375 , 0.7109375 ,        nan,        nan,        nan,\n",
       "        0.765625  , 0.7578125 , 0.734375  , 0.765625  , 0.76171875,\n",
       "        0.7421875 ,        nan,        nan,        nan, 0.73828125,\n",
       "        0.7109375 , 0.6953125 , 0.73828125, 0.71484375, 0.671875  ,\n",
       "               nan,        nan,        nan, 0.765625  , 0.74609375,\n",
       "        0.70703125, 0.765625  , 0.74609375, 0.69921875,        nan,\n",
       "               nan,        nan, 0.734375  , 0.72265625, 0.671875  ,\n",
       "        0.734375  , 0.72265625, 0.67578125,        nan,        nan,\n",
       "               nan, 0.765625  , 0.75390625, 0.69140625, 0.765625  ,\n",
       "        0.74609375, 0.70703125,        nan,        nan,        nan,\n",
       "        0.734375  , 0.734375  , 0.6640625 , 0.734375  , 0.73828125,\n",
       "        0.66015625,        nan,        nan,        nan, 0.765625  ,\n",
       "        0.7421875 , 0.69140625, 0.765625  , 0.74609375, 0.67578125,\n",
       "               nan,        nan,        nan, 0.734375  , 0.7265625 ,\n",
       "        0.66015625, 0.734375  , 0.7265625 , 0.64453125,        nan,\n",
       "               nan,        nan, 0.76171875, 0.7421875 , 0.68359375,\n",
       "        0.76171875, 0.7421875 , 0.67578125,        nan,        nan,\n",
       "               nan, 0.73828125, 0.73828125, 0.66796875, 0.73828125,\n",
       "        0.73828125, 0.67578125,        nan,        nan,        nan,\n",
       "        0.765625  , 0.73828125, 0.671875  , 0.765625  , 0.73828125,\n",
       "        0.69140625,        nan,        nan,        nan, 0.73828125,\n",
       "        0.734375  , 0.68359375, 0.73828125, 0.734375  , 0.66796875,\n",
       "               nan,        nan,        nan, 0.765625  , 0.734375  ,\n",
       "        0.66796875, 0.765625  , 0.734375  , 0.6875    ,        nan,\n",
       "               nan,        nan, 0.734375  , 0.7265625 , 0.67578125,\n",
       "        0.734375  , 0.71875   , 0.67578125,        nan,        nan,\n",
       "               nan, 0.765625  , 0.734375  , 0.69921875, 0.765625  ,\n",
       "        0.73828125, 0.6796875 ,        nan,        nan,        nan,\n",
       "        0.734375  , 0.72265625, 0.66796875, 0.734375  , 0.72265625,\n",
       "        0.65234375,        nan,        nan,        nan, 0.765625  ,\n",
       "        0.73046875, 0.6953125 , 0.765625  , 0.73046875, 0.6953125 ,\n",
       "               nan,        nan,        nan, 0.734375  , 0.72265625,\n",
       "        0.671875  , 0.734375  , 0.72265625, 0.65625   ,        nan,\n",
       "               nan,        nan, 0.765625  , 0.73828125, 0.68359375,\n",
       "        0.765625  , 0.734375  , 0.68359375,        nan,        nan,\n",
       "               nan]),\n",
       " 'split1_test_score': array([0.7109375 , 0.671875  , 0.703125  , 0.7109375 , 0.671875  ,\n",
       "        0.70703125,        nan,        nan,        nan, 0.734375  ,\n",
       "        0.7421875 , 0.71875   , 0.734375  , 0.73828125, 0.70703125,\n",
       "               nan,        nan,        nan, 0.7109375 , 0.6953125 ,\n",
       "        0.72265625, 0.7109375 , 0.6953125 , 0.72265625,        nan,\n",
       "               nan,        nan, 0.73046875, 0.73828125, 0.71875   ,\n",
       "        0.73046875, 0.73828125, 0.71875   ,        nan,        nan,\n",
       "               nan, 0.71875   , 0.703125  , 0.6796875 , 0.71875   ,\n",
       "        0.69921875, 0.7109375 ,        nan,        nan,        nan,\n",
       "        0.72265625, 0.75      , 0.71484375, 0.72265625, 0.75      ,\n",
       "        0.71484375,        nan,        nan,        nan, 0.72265625,\n",
       "        0.7265625 , 0.68359375, 0.72265625, 0.7265625 , 0.67578125,\n",
       "               nan,        nan,        nan, 0.734375  , 0.76171875,\n",
       "        0.71484375, 0.734375  , 0.76171875, 0.703125  ,        nan,\n",
       "               nan,        nan, 0.72265625, 0.72265625, 0.67578125,\n",
       "        0.72265625, 0.7265625 , 0.67578125,        nan,        nan,\n",
       "               nan, 0.734375  , 0.7421875 , 0.71484375, 0.734375  ,\n",
       "        0.7421875 , 0.7109375 ,        nan,        nan,        nan,\n",
       "        0.72265625, 0.7265625 , 0.6328125 , 0.72265625, 0.7265625 ,\n",
       "        0.6328125 ,        nan,        nan,        nan, 0.734375  ,\n",
       "        0.73828125, 0.703125  , 0.734375  , 0.73828125, 0.703125  ,\n",
       "               nan,        nan,        nan, 0.72265625, 0.7265625 ,\n",
       "        0.62890625, 0.72265625, 0.7265625 , 0.6171875 ,        nan,\n",
       "               nan,        nan, 0.734375  , 0.74609375, 0.70703125,\n",
       "        0.734375  , 0.74609375, 0.703125  ,        nan,        nan,\n",
       "               nan, 0.72265625, 0.73046875, 0.6328125 , 0.72265625,\n",
       "        0.73046875, 0.62109375,        nan,        nan,        nan,\n",
       "        0.734375  , 0.75      , 0.70703125, 0.734375  , 0.75      ,\n",
       "        0.703125  ,        nan,        nan,        nan, 0.72265625,\n",
       "        0.7265625 , 0.640625  , 0.72265625, 0.7265625 , 0.640625  ,\n",
       "               nan,        nan,        nan, 0.734375  , 0.74609375,\n",
       "        0.6953125 , 0.734375  , 0.74609375, 0.6953125 ,        nan,\n",
       "               nan,        nan, 0.72265625, 0.71484375, 0.609375  ,\n",
       "        0.72265625, 0.71484375, 0.6484375 ,        nan,        nan,\n",
       "               nan, 0.73046875, 0.7421875 , 0.6953125 , 0.73046875,\n",
       "        0.74609375, 0.6953125 ,        nan,        nan,        nan,\n",
       "        0.72265625, 0.70703125, 0.62890625, 0.72265625, 0.703125  ,\n",
       "        0.6328125 ,        nan,        nan,        nan, 0.734375  ,\n",
       "        0.73046875, 0.6953125 , 0.734375  , 0.73046875, 0.6953125 ,\n",
       "               nan,        nan,        nan, 0.72265625, 0.69921875,\n",
       "        0.6328125 , 0.72265625, 0.69921875, 0.62890625,        nan,\n",
       "               nan,        nan, 0.734375  , 0.73046875, 0.69921875,\n",
       "        0.734375  , 0.73046875, 0.69921875,        nan,        nan,\n",
       "               nan]),\n",
       " 'split2_test_score': array([0.80078125, 0.74609375, 0.796875  , 0.80078125, 0.74609375,\n",
       "        0.78125   ,        nan,        nan,        nan, 0.7890625 ,\n",
       "        0.69921875, 0.796875  , 0.7890625 , 0.69921875, 0.79296875,\n",
       "               nan,        nan,        nan, 0.80078125, 0.78515625,\n",
       "        0.76953125, 0.80078125, 0.78515625, 0.76953125,        nan,\n",
       "               nan,        nan, 0.7890625 , 0.7890625 , 0.78515625,\n",
       "        0.7890625 , 0.7890625 , 0.78125   ,        nan,        nan,\n",
       "               nan, 0.80078125, 0.78515625, 0.73828125, 0.80078125,\n",
       "        0.78515625, 0.71875   ,        nan,        nan,        nan,\n",
       "        0.78515625, 0.79296875, 0.75390625, 0.78515625, 0.79296875,\n",
       "        0.74609375,        nan,        nan,        nan, 0.80078125,\n",
       "        0.78125   , 0.6875    , 0.80078125, 0.78125   , 0.69921875,\n",
       "               nan,        nan,        nan, 0.78515625, 0.796875  ,\n",
       "        0.70703125, 0.78515625, 0.796875  , 0.72265625,        nan,\n",
       "               nan,        nan, 0.80078125, 0.7734375 , 0.671875  ,\n",
       "        0.80078125, 0.765625  , 0.68359375,        nan,        nan,\n",
       "               nan, 0.78515625, 0.7890625 , 0.70703125, 0.78515625,\n",
       "        0.78515625, 0.703125  ,        nan,        nan,        nan,\n",
       "        0.80078125, 0.78125   , 0.67578125, 0.80078125, 0.77734375,\n",
       "        0.67578125,        nan,        nan,        nan, 0.78515625,\n",
       "        0.80078125, 0.703125  , 0.78515625, 0.80078125, 0.68359375,\n",
       "               nan,        nan,        nan, 0.80078125, 0.76953125,\n",
       "        0.65234375, 0.80078125, 0.765625  , 0.66015625,        nan,\n",
       "               nan,        nan, 0.78515625, 0.8125    , 0.6875    ,\n",
       "        0.78515625, 0.81640625, 0.6953125 ,        nan,        nan,\n",
       "               nan, 0.80078125, 0.76171875, 0.66015625, 0.80078125,\n",
       "        0.7578125 , 0.6796875 ,        nan,        nan,        nan,\n",
       "        0.78515625, 0.8203125 , 0.6796875 , 0.78515625, 0.8203125 ,\n",
       "        0.6875    ,        nan,        nan,        nan, 0.80078125,\n",
       "        0.7578125 , 0.66015625, 0.80078125, 0.76171875, 0.6640625 ,\n",
       "               nan,        nan,        nan, 0.78515625, 0.8203125 ,\n",
       "        0.69140625, 0.78515625, 0.81640625, 0.703125  ,        nan,\n",
       "               nan,        nan, 0.80078125, 0.765625  , 0.64453125,\n",
       "        0.80078125, 0.76953125, 0.66015625,        nan,        nan,\n",
       "               nan, 0.78515625, 0.81640625, 0.6875    , 0.78515625,\n",
       "        0.8046875 , 0.6875    ,        nan,        nan,        nan,\n",
       "        0.80078125, 0.76953125, 0.6484375 , 0.80078125, 0.765625  ,\n",
       "        0.66796875,        nan,        nan,        nan, 0.78515625,\n",
       "        0.80078125, 0.6953125 , 0.78515625, 0.80078125, 0.6796875 ,\n",
       "               nan,        nan,        nan, 0.80078125, 0.76171875,\n",
       "        0.66015625, 0.80078125, 0.76171875, 0.671875  ,        nan,\n",
       "               nan,        nan, 0.78515625, 0.8046875 , 0.69921875,\n",
       "        0.78515625, 0.80859375, 0.6796875 ,        nan,        nan,\n",
       "               nan]),\n",
       " 'mean_test_score': array([0.74609375, 0.7109375 , 0.74348958, 0.74609375, 0.7109375 ,\n",
       "        0.73958333,        nan,        nan,        nan, 0.76432292,\n",
       "        0.73046875, 0.76041667, 0.76432292, 0.73046875, 0.75520833,\n",
       "               nan,        nan,        nan, 0.74739583, 0.734375  ,\n",
       "        0.73828125, 0.74739583, 0.734375  , 0.7421875 ,        nan,\n",
       "               nan,        nan, 0.76171875, 0.76822917, 0.74869792,\n",
       "        0.76171875, 0.76692708, 0.74739583,        nan,        nan,\n",
       "               nan, 0.75260417, 0.73307292, 0.7109375 , 0.75260417,\n",
       "        0.73177083, 0.71354167,        nan,        nan,        nan,\n",
       "        0.7578125 , 0.76692708, 0.734375  , 0.7578125 , 0.76822917,\n",
       "        0.734375  ,        nan,        nan,        nan, 0.75390625,\n",
       "        0.73958333, 0.68880208, 0.75390625, 0.74088542, 0.68229167,\n",
       "               nan,        nan,        nan, 0.76171875, 0.76822917,\n",
       "        0.70963542, 0.76171875, 0.76822917, 0.70833333,        nan,\n",
       "               nan,        nan, 0.75260417, 0.73958333, 0.67317708,\n",
       "        0.75260417, 0.73828125, 0.67838542,        nan,        nan,\n",
       "               nan, 0.76171875, 0.76171875, 0.70442708, 0.76171875,\n",
       "        0.7578125 , 0.70703125,        nan,        nan,        nan,\n",
       "        0.75260417, 0.74739583, 0.65755208, 0.75260417, 0.74739583,\n",
       "        0.65625   ,        nan,        nan,        nan, 0.76171875,\n",
       "        0.76041667, 0.69921875, 0.76171875, 0.76171875, 0.6875    ,\n",
       "               nan,        nan,        nan, 0.75260417, 0.74088542,\n",
       "        0.64713542, 0.75260417, 0.73958333, 0.640625  ,        nan,\n",
       "               nan,        nan, 0.76041667, 0.76692708, 0.69270833,\n",
       "        0.76041667, 0.76822917, 0.69140625,        nan,        nan,\n",
       "               nan, 0.75390625, 0.74348958, 0.65364583, 0.75390625,\n",
       "        0.7421875 , 0.65885417,        nan,        nan,        nan,\n",
       "        0.76171875, 0.76953125, 0.68619792, 0.76171875, 0.76953125,\n",
       "        0.69401042,        nan,        nan,        nan, 0.75390625,\n",
       "        0.73958333, 0.66145833, 0.75390625, 0.74088542, 0.65755208,\n",
       "               nan,        nan,        nan, 0.76171875, 0.76692708,\n",
       "        0.68489583, 0.76171875, 0.765625  , 0.6953125 ,        nan,\n",
       "               nan,        nan, 0.75260417, 0.73567708, 0.64322917,\n",
       "        0.75260417, 0.734375  , 0.66145833,        nan,        nan,\n",
       "               nan, 0.76041667, 0.76432292, 0.69401042, 0.76041667,\n",
       "        0.76302083, 0.6875    ,        nan,        nan,        nan,\n",
       "        0.75260417, 0.73307292, 0.6484375 , 0.75260417, 0.73046875,\n",
       "        0.65104167,        nan,        nan,        nan, 0.76171875,\n",
       "        0.75390625, 0.6953125 , 0.76171875, 0.75390625, 0.69010417,\n",
       "               nan,        nan,        nan, 0.75260417, 0.72786458,\n",
       "        0.65494792, 0.75260417, 0.72786458, 0.65234375,        nan,\n",
       "               nan,        nan, 0.76171875, 0.7578125 , 0.69401042,\n",
       "        0.76171875, 0.7578125 , 0.6875    ,        nan,        nan,\n",
       "               nan]),\n",
       " 'std_test_score': array([0.03919249, 0.03042532, 0.03936515, 0.03919249, 0.03042532,\n",
       "        0.03097754,        nan,        nan,        nan, 0.0226278 ,\n",
       "        0.02232608, 0.03210632, 0.0226278 , 0.02299938, 0.0358487 ,\n",
       "               nan,        nan,        nan, 0.03858212, 0.03760294,\n",
       "        0.02209709, 0.03858212, 0.03760294, 0.01991804,        nan,\n",
       "               nan,        nan, 0.02407974, 0.02171007, 0.02749832,\n",
       "        0.02407974, 0.02123634, 0.02577993,        nan,        nan,\n",
       "               nan, 0.03498705, 0.03696633, 0.02407974, 0.03498705,\n",
       "        0.03805114, 0.00368285,        nan,        nan,        nan,\n",
       "        0.02610669, 0.01868841, 0.0159472 , 0.02610669, 0.01813592,\n",
       "        0.01390245,        nan,        nan,        nan, 0.03375386,\n",
       "        0.03014541, 0.00487195, 0.03375386, 0.02894025, 0.01207502,\n",
       "               nan,        nan,        nan, 0.02091456, 0.02123634,\n",
       "        0.00368285, 0.02091456, 0.02123634, 0.01025261,        nan,\n",
       "               nan,        nan, 0.03440064, 0.02393851, 0.00184142,\n",
       "        0.03440064, 0.0194006 , 0.00368285,        nan,        nan,\n",
       "               nan, 0.02091456, 0.01991804, 0.0097439 , 0.02091456,\n",
       "        0.0194006 , 0.00318944,        nan,        nan,        nan,\n",
       "        0.03440064, 0.02415005, 0.01813592, 0.03440064, 0.02171007,\n",
       "        0.01775805,        nan,        nan,        nan, 0.02091456,\n",
       "        0.02858659, 0.00552427, 0.02091456, 0.02780489, 0.01149969,\n",
       "               nan,        nan,        nan, 0.03440064, 0.02025566,\n",
       "        0.0132787 , 0.03440064, 0.01841424, 0.01775805,        nan,\n",
       "               nan,        nan, 0.02075179, 0.03226435, 0.01025261,\n",
       "        0.02075179, 0.03410365, 0.01149969,        nan,        nan,\n",
       "               nan, 0.03375386, 0.0132787 , 0.0150727 , 0.03375386,\n",
       "        0.01149969, 0.02674823,        nan,        nan,        nan,\n",
       "        0.02091456, 0.03622507, 0.0150727 , 0.02091456, 0.03622507,\n",
       "        0.00663935,        nan,        nan,        nan, 0.03375386,\n",
       "        0.0132787 , 0.01756606, 0.03375386, 0.0150727 , 0.01207502,\n",
       "               nan,        nan,        nan, 0.02091456, 0.03805114,\n",
       "        0.01207502, 0.02091456, 0.03622507, 0.00637888,        nan,\n",
       "               nan,        nan, 0.03440064, 0.02171007, 0.02712587,\n",
       "        0.03440064, 0.02491032, 0.01120094,        nan,        nan,\n",
       "               nan, 0.0226278 , 0.03696633, 0.00487195, 0.0226278 ,\n",
       "        0.02963491, 0.00637888,        nan,        nan,        nan,\n",
       "        0.03440064, 0.02655739, 0.0159472 , 0.03440064, 0.02610669,\n",
       "        0.01438198,        nan,        nan,        nan, 0.02091456,\n",
       "        0.03314563, 0.        , 0.02091456, 0.03314563, 0.0073657 ,\n",
       "               nan,        nan,        nan, 0.03440064, 0.02577993,\n",
       "        0.01636693, 0.03440064, 0.02577993, 0.01775805,        nan,\n",
       "               nan,        nan, 0.02091456, 0.03329873, 0.0073657 ,\n",
       "        0.02091456, 0.03594316, 0.00843846,        nan,        nan,\n",
       "               nan]),\n",
       " 'rank_test_score': array([ 75, 106,  77,  75, 106,  84, 186, 185, 184,  13, 100,  35,  13,\n",
       "        100,  46, 183, 182, 181,  70,  92,  89,  70,  92,  79, 180, 179,\n",
       "        178,  17,   3,  69,  17,   8,  70, 177, 176, 175,  55,  97, 106,\n",
       "         55,  99, 105, 174, 173, 172,  41,   8,  92,  41,   3,  92, 171,\n",
       "        170, 169,  47,  84, 122,  47,  81, 128, 168, 167, 166,  17,   3,\n",
       "        109,  17,   3, 110, 165, 164, 187,  55,  84, 130,  55,  89, 129,\n",
       "        188, 189, 190,  17,  17, 112,  17,  41, 111, 214, 213, 212,  55,\n",
       "         70, 134,  55,  70, 136, 211, 210, 209,  17,  35, 113,  17,  17,\n",
       "        123, 208, 207, 162,  55,  81, 142,  55,  84, 144, 205, 204, 215,\n",
       "         35,   8, 119,  35,   3, 120, 203, 201, 200,  47,  77, 138,  47,\n",
       "         79, 133, 199, 198, 197,  17,   1, 126,  17,   1, 116, 196, 195,\n",
       "        194,  47,  84, 131,  47,  81, 134, 193, 192, 191,  17,   8, 127,\n",
       "         17,  12, 114, 163, 202, 161,  55,  91, 143,  55,  92, 131, 160,\n",
       "        146, 147,  35,  13, 116,  35,  16, 123, 148, 149, 150,  55,  97,\n",
       "        141,  55, 100, 140, 151, 145, 152,  17,  47, 114,  17,  47, 121,\n",
       "        153, 154, 155,  55, 103, 137,  55, 103, 139, 156, 157, 158,  17,\n",
       "         41, 116,  17,  41, 123, 159, 206, 216]),\n",
       " 'split0_train_score': array([0.78320312, 0.73046875, 0.76757812, 0.78320312, 0.72851562,\n",
       "        0.76757812,        nan,        nan,        nan, 0.78125   ,\n",
       "        0.75195312, 0.76171875, 0.78125   , 0.75585938, 0.76171875,\n",
       "               nan,        nan,        nan, 0.78515625, 0.76367188,\n",
       "        0.75      , 0.78515625, 0.765625  , 0.75390625,        nan,\n",
       "               nan,        nan, 0.78125   , 0.8046875 , 0.75976562,\n",
       "        0.78125   , 0.80664062, 0.76171875,        nan,        nan,\n",
       "               nan, 0.78320312, 0.80664062, 0.70507812, 0.78320312,\n",
       "        0.80664062, 0.71484375,        nan,        nan,        nan,\n",
       "        0.78125   , 0.82421875, 0.72070312, 0.78125   , 0.82226562,\n",
       "        0.7265625 ,        nan,        nan,        nan, 0.78320312,\n",
       "        0.85742188, 0.64648438, 0.78320312, 0.85546875, 0.65039062,\n",
       "               nan,        nan,        nan, 0.77734375, 0.859375  ,\n",
       "        0.67773438, 0.77734375, 0.859375  , 0.66210938,        nan,\n",
       "               nan,        nan, 0.78320312, 0.86914062, 0.640625  ,\n",
       "        0.78320312, 0.86914062, 0.64257812,        nan,        nan,\n",
       "               nan, 0.77929688, 0.87109375, 0.6640625 , 0.77929688,\n",
       "        0.87304688, 0.66992188,        nan,        nan,        nan,\n",
       "        0.78320312, 0.87109375, 0.65234375, 0.78320312, 0.86914062,\n",
       "        0.65039062,        nan,        nan,        nan, 0.77929688,\n",
       "        0.8828125 , 0.66992188, 0.77929688, 0.88085938, 0.66601562,\n",
       "               nan,        nan,        nan, 0.78320312, 0.87695312,\n",
       "        0.64257812, 0.78320312, 0.87304688, 0.63671875,        nan,\n",
       "               nan,        nan, 0.77929688, 0.88867188, 0.66015625,\n",
       "        0.77929688, 0.88671875, 0.6640625 ,        nan,        nan,\n",
       "               nan, 0.78320312, 0.88476562, 0.6328125 , 0.78320312,\n",
       "        0.88085938, 0.65234375,        nan,        nan,        nan,\n",
       "        0.77929688, 0.89648438, 0.66210938, 0.77929688, 0.89648438,\n",
       "        0.67773438,        nan,        nan,        nan, 0.78320312,\n",
       "        0.89648438, 0.63476562, 0.78320312, 0.89648438, 0.64648438,\n",
       "               nan,        nan,        nan, 0.77929688, 0.90429688,\n",
       "        0.66992188, 0.77929688, 0.90234375, 0.67578125,        nan,\n",
       "               nan,        nan, 0.78320312, 0.90039062, 0.64257812,\n",
       "        0.78320312, 0.8984375 , 0.63867188,        nan,        nan,\n",
       "               nan, 0.77929688, 0.91210938, 0.67382812, 0.77929688,\n",
       "        0.91015625, 0.67382812,        nan,        nan,        nan,\n",
       "        0.78320312, 0.91015625, 0.63867188, 0.78320312, 0.90234375,\n",
       "        0.640625  ,        nan,        nan,        nan, 0.77929688,\n",
       "        0.921875  , 0.671875  , 0.77929688, 0.91796875, 0.66992188,\n",
       "               nan,        nan,        nan, 0.78320312, 0.91210938,\n",
       "        0.64453125, 0.78320312, 0.91210938, 0.65625   ,        nan,\n",
       "               nan,        nan, 0.77929688, 0.92382812, 0.66992188,\n",
       "        0.77929688, 0.92382812, 0.66601562,        nan,        nan,\n",
       "               nan]),\n",
       " 'split1_train_score': array([0.765625  , 0.734375  , 0.76367188, 0.765625  , 0.734375  ,\n",
       "        0.76367188,        nan,        nan,        nan, 0.77734375,\n",
       "        0.77734375, 0.76953125, 0.77734375, 0.77734375, 0.765625  ,\n",
       "               nan,        nan,        nan, 0.77148438, 0.765625  ,\n",
       "        0.74609375, 0.77148438, 0.765625  , 0.74414062,        nan,\n",
       "               nan,        nan, 0.77539062, 0.81054688, 0.76757812,\n",
       "        0.77539062, 0.80859375, 0.76757812,        nan,        nan,\n",
       "               nan, 0.77539062, 0.7890625 , 0.73046875, 0.77539062,\n",
       "        0.7890625 , 0.73242188,        nan,        nan,        nan,\n",
       "        0.77539062, 0.80859375, 0.73828125, 0.77539062, 0.80859375,\n",
       "        0.71289062,        nan,        nan,        nan, 0.77734375,\n",
       "        0.8359375 , 0.66992188, 0.77734375, 0.8359375 , 0.66601562,\n",
       "               nan,        nan,        nan, 0.77734375, 0.8515625 ,\n",
       "        0.671875  , 0.77734375, 0.8515625 , 0.67773438,        nan,\n",
       "               nan,        nan, 0.77734375, 0.8515625 , 0.66210938,\n",
       "        0.77734375, 0.8515625 , 0.6640625 ,        nan,        nan,\n",
       "               nan, 0.77734375, 0.86328125, 0.67773438, 0.77734375,\n",
       "        0.86132812, 0.67382812,        nan,        nan,        nan,\n",
       "        0.77734375, 0.86132812, 0.67773438, 0.77734375, 0.86132812,\n",
       "        0.68164062,        nan,        nan,        nan, 0.77734375,\n",
       "        0.87695312, 0.671875  , 0.77734375, 0.875     , 0.671875  ,\n",
       "               nan,        nan,        nan, 0.77148438, 0.875     ,\n",
       "        0.68164062, 0.77148438, 0.875     , 0.66796875,        nan,\n",
       "               nan,        nan, 0.77734375, 0.87695312, 0.671875  ,\n",
       "        0.77734375, 0.87695312, 0.671875  ,        nan,        nan,\n",
       "               nan, 0.7734375 , 0.87890625, 0.6796875 , 0.7734375 ,\n",
       "        0.87890625, 0.6796875 ,        nan,        nan,        nan,\n",
       "        0.77734375, 0.88476562, 0.66992188, 0.77734375, 0.88476562,\n",
       "        0.671875  ,        nan,        nan,        nan, 0.77148438,\n",
       "        0.88476562, 0.67578125, 0.77148438, 0.88476562, 0.67578125,\n",
       "               nan,        nan,        nan, 0.77734375, 0.890625  ,\n",
       "        0.66992188, 0.77734375, 0.890625  , 0.66992188,        nan,\n",
       "               nan,        nan, 0.77148438, 0.88867188, 0.68164062,\n",
       "        0.77148438, 0.88867188, 0.6875    ,        nan,        nan,\n",
       "               nan, 0.77734375, 0.89453125, 0.66796875, 0.77734375,\n",
       "        0.89453125, 0.66796875,        nan,        nan,        nan,\n",
       "        0.77148438, 0.89648438, 0.6796875 , 0.77148438, 0.89648438,\n",
       "        0.67578125,        nan,        nan,        nan, 0.77734375,\n",
       "        0.8984375 , 0.66796875, 0.77734375, 0.8984375 , 0.66796875,\n",
       "               nan,        nan,        nan, 0.7734375 , 0.89453125,\n",
       "        0.67773438, 0.7734375 , 0.89453125, 0.67773438,        nan,\n",
       "               nan,        nan, 0.77734375, 0.90039062, 0.66601562,\n",
       "        0.77734375, 0.8984375 , 0.66601562,        nan,        nan,\n",
       "               nan]),\n",
       " 'split2_train_score': array([0.75      , 0.69921875, 0.7265625 , 0.75      , 0.69921875,\n",
       "        0.72460938,        nan,        nan,        nan, 0.77734375,\n",
       "        0.70507812, 0.75      , 0.77734375, 0.703125  , 0.75195312,\n",
       "               nan,        nan,        nan, 0.75390625, 0.73242188,\n",
       "        0.72265625, 0.75390625, 0.73242188, 0.72265625,        nan,\n",
       "               nan,        nan, 0.7734375 , 0.80273438, 0.74023438,\n",
       "        0.7734375 , 0.80273438, 0.74023438,        nan,        nan,\n",
       "               nan, 0.75390625, 0.7734375 , 0.66992188, 0.75390625,\n",
       "        0.7734375 , 0.6640625 ,        nan,        nan,        nan,\n",
       "        0.77539062, 0.79882812, 0.68164062, 0.77539062, 0.79882812,\n",
       "        0.68359375,        nan,        nan,        nan, 0.75585938,\n",
       "        0.81640625, 0.63085938, 0.75585938, 0.81640625, 0.6328125 ,\n",
       "               nan,        nan,        nan, 0.77148438, 0.82226562,\n",
       "        0.67382812, 0.77148438, 0.82421875, 0.6640625 ,        nan,\n",
       "               nan,        nan, 0.75585938, 0.83398438, 0.61328125,\n",
       "        0.75585938, 0.83789062, 0.62304688,        nan,        nan,\n",
       "               nan, 0.77148438, 0.84570312, 0.66015625, 0.77148438,\n",
       "        0.84765625, 0.65039062,        nan,        nan,        nan,\n",
       "        0.75585938, 0.84960938, 0.625     , 0.75585938, 0.85351562,\n",
       "        0.62695312,        nan,        nan,        nan, 0.7734375 ,\n",
       "        0.84765625, 0.64257812, 0.7734375 , 0.84960938, 0.65429688,\n",
       "               nan,        nan,        nan, 0.75585938, 0.85546875,\n",
       "        0.60742188, 0.75585938, 0.85742188, 0.61914062,        nan,\n",
       "               nan,        nan, 0.7734375 , 0.86132812, 0.65039062,\n",
       "        0.7734375 , 0.86328125, 0.65429688,        nan,        nan,\n",
       "               nan, 0.75585938, 0.85742188, 0.61914062, 0.75585938,\n",
       "        0.86132812, 0.62109375,        nan,        nan,        nan,\n",
       "        0.7734375 , 0.86132812, 0.65625   , 0.7734375 , 0.86132812,\n",
       "        0.64453125,        nan,        nan,        nan, 0.75390625,\n",
       "        0.86132812, 0.62890625, 0.75390625, 0.86132812, 0.61914062,\n",
       "               nan,        nan,        nan, 0.7734375 , 0.86523438,\n",
       "        0.64257812, 0.7734375 , 0.86523438, 0.64648438,        nan,\n",
       "               nan,        nan, 0.75390625, 0.86523438, 0.609375  ,\n",
       "        0.75390625, 0.86523438, 0.625     ,        nan,        nan,\n",
       "               nan, 0.7734375 , 0.8671875 , 0.64453125, 0.7734375 ,\n",
       "        0.87109375, 0.64453125,        nan,        nan,        nan,\n",
       "        0.75585938, 0.86523438, 0.61132812, 0.75585938, 0.8671875 ,\n",
       "        0.625     ,        nan,        nan,        nan, 0.7734375 ,\n",
       "        0.87695312, 0.65039062, 0.7734375 , 0.8828125 , 0.65625   ,\n",
       "               nan,        nan,        nan, 0.75390625, 0.86914062,\n",
       "        0.62304688, 0.75390625, 0.87109375, 0.62304688,        nan,\n",
       "               nan,        nan, 0.7734375 , 0.88476562, 0.64453125,\n",
       "        0.7734375 , 0.88867188, 0.65820312,        nan,        nan,\n",
       "               nan]),\n",
       " 'mean_train_score': array([0.76627604, 0.72135417, 0.75260417, 0.76627604, 0.72070312,\n",
       "        0.75195312,        nan,        nan,        nan, 0.77864583,\n",
       "        0.74479167, 0.76041667, 0.77864583, 0.74544271, 0.75976562,\n",
       "               nan,        nan,        nan, 0.77018229, 0.75390625,\n",
       "        0.73958333, 0.77018229, 0.75455729, 0.74023438,        nan,\n",
       "               nan,        nan, 0.77669271, 0.80598958, 0.75585938,\n",
       "        0.77669271, 0.80598958, 0.75651042,        nan,        nan,\n",
       "               nan, 0.77083333, 0.78971354, 0.70182292, 0.77083333,\n",
       "        0.78971354, 0.70377604,        nan,        nan,        nan,\n",
       "        0.77734375, 0.81054688, 0.71354167, 0.77734375, 0.80989583,\n",
       "        0.70768229,        nan,        nan,        nan, 0.77213542,\n",
       "        0.83658854, 0.64908854, 0.77213542, 0.8359375 , 0.64973958,\n",
       "               nan,        nan,        nan, 0.77539062, 0.84440104,\n",
       "        0.67447917, 0.77539062, 0.84505208, 0.66796875,        nan,\n",
       "               nan,        nan, 0.77213542, 0.8515625 , 0.63867188,\n",
       "        0.77213542, 0.85286458, 0.64322917,        nan,        nan,\n",
       "               nan, 0.77604167, 0.86002604, 0.66731771, 0.77604167,\n",
       "        0.86067708, 0.66471354,        nan,        nan,        nan,\n",
       "        0.77213542, 0.86067708, 0.65169271, 0.77213542, 0.86132812,\n",
       "        0.65299479,        nan,        nan,        nan, 0.77669271,\n",
       "        0.86914062, 0.66145833, 0.77669271, 0.86848958, 0.6640625 ,\n",
       "               nan,        nan,        nan, 0.77018229, 0.86914062,\n",
       "        0.64388021, 0.77018229, 0.86848958, 0.64127604,        nan,\n",
       "               nan,        nan, 0.77669271, 0.87565104, 0.66080729,\n",
       "        0.77669271, 0.87565104, 0.66341146,        nan,        nan,\n",
       "               nan, 0.77083333, 0.87369792, 0.64388021, 0.77083333,\n",
       "        0.87369792, 0.65104167,        nan,        nan,        nan,\n",
       "        0.77669271, 0.88085938, 0.66276042, 0.77669271, 0.88085938,\n",
       "        0.66471354,        nan,        nan,        nan, 0.76953125,\n",
       "        0.88085938, 0.64648438, 0.76953125, 0.88085938, 0.64713542,\n",
       "               nan,        nan,        nan, 0.77669271, 0.88671875,\n",
       "        0.66080729, 0.77669271, 0.88606771, 0.6640625 ,        nan,\n",
       "               nan,        nan, 0.76953125, 0.88476562, 0.64453125,\n",
       "        0.76953125, 0.88411458, 0.65039062,        nan,        nan,\n",
       "               nan, 0.77669271, 0.89127604, 0.66210938, 0.77669271,\n",
       "        0.89192708, 0.66210938,        nan,        nan,        nan,\n",
       "        0.77018229, 0.890625  , 0.64322917, 0.77018229, 0.88867188,\n",
       "        0.64713542,        nan,        nan,        nan, 0.77669271,\n",
       "        0.89908854, 0.66341146, 0.77669271, 0.89973958, 0.66471354,\n",
       "               nan,        nan,        nan, 0.77018229, 0.89192708,\n",
       "        0.6484375 , 0.77018229, 0.89257812, 0.65234375,        nan,\n",
       "               nan,        nan, 0.77669271, 0.90299479, 0.66015625,\n",
       "        0.77669271, 0.90364583, 0.66341146,        nan,        nan,\n",
       "               nan]),\n",
       " 'std_train_score': array([0.01356293, 0.01573313, 0.01848316, 0.01356293, 0.01537892,\n",
       "        0.0194006 ,        nan,        nan,        nan, 0.00184142,\n",
       "        0.02993376, 0.00802658, 0.00184142, 0.03118211, 0.00574984,\n",
       "               nan,        nan,        nan, 0.01279094, 0.01521266,\n",
       "        0.01207502, 0.01279094, 0.0156521 , 0.01305334,        nan,\n",
       "               nan,        nan, 0.00331967, 0.00331967, 0.01149969,\n",
       "        0.00331967, 0.00243597, 0.01175486,        nan,        nan,\n",
       "               nan, 0.01238691, 0.01356293, 0.0248251 , 0.01238691,\n",
       "        0.01356293, 0.02898415,        nan,        nan,        nan,\n",
       "        0.00276214, 0.01045728, 0.02367143, 0.00276214, 0.00961252,\n",
       "        0.01792435,        nan,        nan,        nan, 0.01175486,\n",
       "        0.01675089, 0.01605316, 0.01175486, 0.0159472 , 0.01356293,\n",
       "               nan,        nan,        nan, 0.00276214, 0.01597376,\n",
       "        0.00243597, 0.00276214, 0.0150727 , 0.00695122,        nan,\n",
       "               nan,        nan, 0.01175486, 0.01435248, 0.01998178,\n",
       "        0.01175486, 0.01279094, 0.01675089,        nan,        nan,\n",
       "               nan, 0.00331967, 0.01061817, 0.00753635, 0.00331967,\n",
       "        0.0103759 , 0.01025261,        nan,        nan,        nan,\n",
       "        0.01175486, 0.00878303, 0.02153364, 0.01175486, 0.00637888,\n",
       "        0.02240189,        nan,        nan,        nan, 0.00243597,\n",
       "        0.01537892, 0.01337411, 0.00243597, 0.01356293, 0.00730792,\n",
       "               nan,        nan,        nan, 0.01120094, 0.0097003 ,\n",
       "        0.03031366, 0.01120094, 0.00786657, 0.02019279,        nan,\n",
       "               nan,        nan, 0.00243597, 0.01120094, 0.00878303,\n",
       "        0.00243597, 0.00961252, 0.00719099,        nan,        nan,\n",
       "               nan, 0.0113139 , 0.01175486, 0.02592748, 0.0113139 ,\n",
       "        0.00878303, 0.02393851,        nan,        nan,        nan,\n",
       "        0.00243597, 0.01461585, 0.00560047, 0.00243597, 0.01461585,\n",
       "        0.01447012,        nan,        nan,        nan, 0.01203987,\n",
       "        0.01461585, 0.02085367, 0.01203987, 0.01461585, 0.02312802,\n",
       "               nan,        nan,        nan, 0.00243597, 0.01618464,\n",
       "        0.01288997, 0.00243597, 0.01548877, 0.0126577 ,        nan,\n",
       "               nan,        nan, 0.01203987, 0.01461585, 0.02953463,\n",
       "        0.01203987, 0.0139329 , 0.02682734,        nan,        nan,\n",
       "               nan, 0.00243597, 0.01848316, 0.0126577 , 0.00243597,\n",
       "        0.01605316, 0.0126577 ,        nan,        nan,        nan,\n",
       "        0.01120094, 0.01880147, 0.02809303, 0.01120094, 0.01537892,\n",
       "        0.02123634,        nan,        nan,        nan, 0.00243597,\n",
       "        0.01834506, 0.00934421, 0.00243597, 0.01438198, 0.00603751,\n",
       "               nan,        nan,        nan, 0.01217987, 0.0176383 ,\n",
       "        0.02249629, 0.01217987, 0.01680142, 0.02249629,        nan,\n",
       "               nan,        nan, 0.00243597, 0.01605316, 0.01116304,\n",
       "        0.00243597, 0.01481746, 0.00368285,        nan,        nan,\n",
       "               nan])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCVSVC.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = GSCVSVC.predict(x_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76953125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCVSVC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше- лучший результат из грида, параметры для предикта будут браться именно от этого фита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8896103896103896"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train = GSCVSVC.predict(x_train).reshape(-1, 1)\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я проверил, аккьюраси выше на 0.1, если передавать всю выборку в грид, нежели только трейновую, так как при скармливании модели большего количества данных, модель может найти больше закономерности в данных, а значит и лучше обучится на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8599348534201955"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93,  6],\n",
       "       [11, 44]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбил акьюраси более менее приемлимое, судя по матрице ошибок- норм, но все таки плоховато со вторым классом работает, но шо поделать... если бы 2 класс был бы важнее, передали бы balanced, потеряли бы в предсказании первого, но зато со вторым почаще попадали бы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, лучше предсказывает моя модель. А так же она лучше справится в случае, если важен именно 2 класс, нежели первый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 4, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'kernel': ['rbf', 'sigmoid'], 'gamma': ['scale', 'auto', 'float'], 'class_weight': ['balanced'], 'C':[0.1,0.2,0.5,2,3,4,5,6,7,8,9,10]}\n",
    "GSCVSVC = GridSearchCV(clf, params, verbose=1, n_jobs=-1, cv=3, return_train_score=True)\n",
    "GSCVSVC.fit(out, Y)\n",
    "pred = GSCVSVC.predict(x_test).reshape(-1, 1)\n",
    "GSCVSVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831168831168831"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86, 13],\n",
       "       [ 5, 50]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге мы получили более точные предсказания на 1 класс, ухудшив предказания на 0 класс,но сделано это было лишь на случай, если вдруг важнее \"выявить всех, у кого есть риск и начать лечить, и нам не страшно, что начнем лечить здорового- зато не пропустим больного, успев вовремя оказать помощь\" В любом случае, моя модель справляется намного лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В гриде перебраны необходимые для 3 задания метод опорных векторов с линейным ядром (SVC);\n",
    "метод опорных векторов с гауссовым ядром (SVC) и даже чуток больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного почитать об SVM (в скитлерне SVC)\n",
    "Плюсы:\n",
    "\n",
    "\n",
    "хорошо работает с пространством признаков большого размера;\n",
    "хорошо работает с данными небольшого объема;\n",
    "алгоритм максимизирует разделяющую полосу, которая, как подушка безопасности, позволяет уменьшить количество ошибок классификации;\n",
    "так как алгоритм сводится к решению задачи квадратичного программирования в выпуклой области, то такая задача всегда имеет единственное решение (разделяющая гиперплоскость с определенными гиперпараметрами алгоритма всегда одна).\n",
    "\n",
    "Минусы:\n",
    "\n",
    "\n",
    "долгое время обучения (для больших наборов данных);\n",
    "неустойчивость к шуму: выбросы в обучающих данных становятся опорными объектами-нарушителями и напрямую влияют на построение разделяющей гиперплоскости;\n",
    "не описаны общие методы построения ядер и спрямляющих пространств, наиболее подходящих для конкретной задачи в случае линейной неразделимости классов. Подбирать полезные преобразования данных – искусство."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'metric':['mahalanobis', 'seuclidean', 'euclidean', 'manhattan', 'chebyshev'],'n_neighbors': [1,2,3,4,5,6,7], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'leaf_size': [5,7,8,10,20,25,35,40,45,50, 60, 5], 'weights': ['uniform','distance'],\n",
    "                        'p': [1,2]}\n",
    "SGDKN = GridSearchCV(clf, params, verbose=1, n_jobs=-1, cv=3)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут и далее буду фитоват по полной выборке по причине, объясненной выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5040 candidates, totalling 15120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2160 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 6160 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 11760 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 15120 out of 15120 | elapsed:   37.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
       "                         'leaf_size': [5, 7, 8, 10, 20, 25, 35, 40, 45, 50, 60,\n",
       "                                       5],\n",
       "                         'metric': ['mahalanobis', 'seuclidean', 'euclidean',\n",
       "                                    'manhattan', 'chebyshev'],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7], 'p': [1, 2],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDKN.fit(out, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701298701298701"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = SGDKN.predict(x_test)\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92,  7],\n",
       "       [13, 42]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute',\n",
       " 'leaf_size': 5,\n",
       " 'metric': 'mahalanobis',\n",
       " 'n_neighbors': 5,\n",
       " 'p': 1,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDKN.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всех себя показала метрика Расстояние Махалано́биса — мера расстояния между векторами случайных величин, обобщающая понятие евклидова расстояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1',\n",
       "       '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1',\n",
       "       '0', '1', '0', '1', '1', '1', '0', '0', '0', '1', '0', '0', '1',\n",
       "       '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1',\n",
       "       '1', '0', '1', '1', '1', '0', '0', '0', '1', '0', '1', '0', '1',\n",
       "       '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '0', '0',\n",
       "       '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0',\n",
       "       '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0',\n",
       "       '0', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0',\n",
       "       '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '0',\n",
       "       '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совсем не густо кнн выбивает, но раз надо, то пусть будет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пара слов о кнн- метод ближайших соседей, находит ближайших соседей к точке, определяет, какого они класса и на основе этого принимает решение о том, какого класса нынешняя точка. Допустим, 3 соседки красные, 1 синяя, значит я- красная точка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании сказано- у меня сделано."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(out, Y)\n",
    "pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35714285714285715"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 99],\n",
       "       [ 0, 55]], dtype=int64)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший акьюраси выбил SVC. Что касается КНН- он отработал слишком плохо, логистическая же регрессия подходит в целом для первоначального анализа датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, \n",
    "                                                    test_size=0.2,\n",
    "                                                   random_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, criterion = 'entropy')\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "import seaborn as sns\n",
    "f, ax = plt.subplots(figsize =(5,5))\n",
    "sns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0, 12,  1],\n",
       "       [ 0,  0,  6]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
